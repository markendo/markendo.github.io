<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Mark Endo</title>
    <link>https://markendo.github.io/</link>
    <description>Recent content in Home on Mark Endo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://markendo.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Retrieval-Based Chest X-Ray Report Generation Using a Pre-trained Contrastive Language-Image Model</title>
      <link>https://markendo.github.io/projects/report-clip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://markendo.github.io/projects/report-clip/</guid>
      <description>Abstract: We propose CXR-RePaiR: a retrieval-based radiology report generation approach using a pre-trained contrastive language-image model. Our method generates clinically accurate reports on both in-distribution and out-of-distribution data. CXR-RePaiR outperforms or matches prior report generation methods on clinical metrics, achieving an average F1 score of 0.352 (Î”+7.98%) on an external radiology dataset (CheXpert). Further, we implement a compression approach used to reduce the size of the reference corpus and speed up the runtime of our retrieval method.</description>
    </item>
    
    <item>
      <title>CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps for X-ray Segmentation</title>
      <link>https://markendo.github.io/projects/chexseg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://markendo.github.io/projects/chexseg/</guid>
      <description>Abstract: Medical image segmentation models are typically supervised by expert annotations at the pixel-level, which can be expensive to acquire. In this work, we propose a method that combines the high quality of pixel-level expert annotations with the scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation models. We demonstrate the application of our semi-supervised method, which we call CheXseg, on multi-label chest X-ray interpretation. We find that CheXseg improves upon the performance (mIoU) of fully-supervised methods that use only pixel-level expert annotations by 9.</description>
    </item>
    
    <item>
      <title>BioXtract: Learning Biomedical Knowledge From General and Random Data</title>
      <link>https://markendo.github.io/projects/bioxtract/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://markendo.github.io/projects/bioxtract/</guid>
      <description>Abstract: The privacy of medical documents and protected healthcare information can oftentimes limit the accessibility of accurate biomedical natural language processing models. Distillation can be used to transfer knowledge from these models, but it typically relies on having related data to distill on. In this work, we investigate the distillation of BERT-based biomedical models using transfer datasets from varying domains, including general data, randomized general data, and biomedical data. We find that general data can be used to learn task-specific biomedical knowledge, especially when we can initialize student models with similar weights to the teacher.</description>
    </item>
    
    <item>
      <title>Tutorial - Knowledge Graph Embeddings: Simplistic and Powerful Representations</title>
      <link>https://markendo.github.io/projects/transe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://markendo.github.io/projects/transe/</guid>
      <description>I created this tutorial as part of the Stanford CS224W course project. In the tutorial, I analyze the power of knowledge graph (KG) embedding representations through the task of predicting missing triples in the Freebase dataset. First, I overview knowledge graphs and discuss the task of predicting missing triplets. Second, I look at a popular dataset used to learn KG models, namely FB15k-237. Third, I implement a popular KG method for learning knowledge graph embeddings (namely TransE) and analyze the results.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://markendo.github.io/about_me/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://markendo.github.io/about_me/</guid>
      <description>Hi! I&amp;rsquo;m an undergraduate researcher at Stanford University with a passion for AI and health. I am currently a junior, studying computer science with a depth in artificial intelligence. My research interest lies in creating deep learning solutions to aid decision making in settings such as medicine. I have published work on developing medical imaging models in radiology to help establish clinician trust. My goal is to tackle high-impact problems and develop systems to better people&amp;rsquo;s lives.</description>
    </item>
    
  </channel>
</rss>
